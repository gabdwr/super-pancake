name: Token Metrics 4x Daily Fetch

# Run 4 times per day (every 6 hours) to collect metrics for all discovered tokens
on:
  schedule:
    # Runs every 6 hours: Midnight, 6 AM, Noon, 6 PM UTC
    - cron: '0 0,6,12,18 * * *'

  # Allow manual triggering from GitHub Actions UI
  workflow_dispatch:

jobs:
  fetch-metrics:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours max (GitHub Actions limit)

    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: ðŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ðŸ”§ Create .env file from secrets
        run: |
          cat > .env << EOF
          SUPABASE_HOST=${{ secrets.SUPABASE_HOST }}
          SUPABASE_PORT=${{ secrets.SUPABASE_PORT }}
          SUPABASE_USERNAME=${{ secrets.SUPABASE_USERNAME }}
          SUPABASE_PASSWORD=${{ secrets.SUPABASE_PASSWORD }}
          SUPABASE_DBNAME=${{ secrets.SUPABASE_DBNAME }}
          TELEGRAM_BOT_TOKEN=${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID=${{ secrets.TELEGRAM_CHAT_ID }}
          SUPABASE_URL=${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY=${{ secrets.SUPABASE_ANON_KEY }}
          EOF

      - name: ðŸ“Š Fetch token metrics
        id: datafetch
        run: |
          python run_datafetch.py
        continue-on-error: true

      - name: ðŸ“ˆ Check results
        run: |
          if [ "${{ steps.datafetch.outcome }}" == "failure" ]; then
            echo "âŒ Data fetch failed"
            exit 1
          else
            echo "âœ… Data fetch completed successfully"
          fi

      - name: ðŸ§¹ Cleanup .env file
        if: always()
        run: |
          rm -f .env

# Workflow summary:
# - Runs 4 times per day: 00:00, 06:00, 12:00, 18:00 UTC (every 6 hours)
# - Fetches metrics for ALL tokens in discovered_tokens table
# - Calls DexScreener API + GoPlus API for each token (with rate limiting & retries)
# - Stores time-series snapshots in time_series_data table
# - Sends Telegram notification with summary
# - Can be manually triggered from GitHub Actions tab
#
# Why every 6 hours?
# - Captures volume_h6 changes perfectly (6-hour volume metric)
# - 4 snapshots/day = 28 data points over 7 days (sufficient for trend analysis)
# - API-friendly: 167 tokens Ã— 4 fetches/day = 668 calls/day (sustainable)
# - Database-friendly: ~20K rows/month (won't hit 500MB limit for years)
#
# Performance notes:
# - ~167 tokens: ~3-5 minutes (with rate limiting & retries)
# - ~300 tokens: ~5-8 minutes
# - ~1000 tokens: ~15-20 minutes
#
# Cron schedule options:
# '0 0,6,12,18 * * *' = Every 6 hours (current)
# '0 0,8,16 * * *'    = Every 8 hours (3x daily)
# '0 0,12 * * *'      = Every 12 hours (2x daily)
# '0 0 * * *'         = Once daily at midnight
